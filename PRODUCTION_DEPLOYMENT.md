# Production Deployment - Render.com & Cloud Optimization

## üåê Production vs Local Development

### Key Differences

| Factor | Local Dev | Production (Render.com) |
|--------|-----------|------------------------|
| **Network Latency** | ~10-50ms | ~100-200ms |
| **Network Stability** | Stable | Variable |
| **VAD Sensitivity** | Can be lower | Must be higher |
| **Silence Duration** | Can be shorter | Must be longer |
| **Total Latency** | 400-600ms | 600-900ms |

## ‚öôÔ∏è Production-Optimized Settings

### Configuration

```python
# agent.py - PRODUCTION Settings
turn_detection=TurnDetection(
    type="server_vad",
    threshold=0.7,              # HIGHER for cloud stability
    prefix_padding_ms=300,      # STANDARD for reliability
    silence_duration_ms=400,    # HIGHER to account for network
)
```

### Why These Values?

| Setting | Value | Reason |
|---------|-------|--------|
| **threshold** | 0.7 | Network jitter can cause false VAD triggers |
| **prefix_padding** | 300ms | Network delays need buffer |
| **silence_duration** | 400ms | Network latency + processing time |

## üìä Expected Latency Breakdown (Production)

```
User speaks: "Hello"
    ‚Üì
[100ms] Network: User ‚Üí Render.com
    ‚Üì
[300ms] Audio capture + VAD detection
    ‚Üì
[400ms] Silence detection (waiting for end of speech)
    ‚Üì
[100ms] Network: Render ‚Üí OpenAI
    ‚Üì
[200ms] OpenAI processing (STT + LLM + TTS)
    ‚Üì
[100ms] Network: OpenAI ‚Üí Render ‚Üí User
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
[900ms] TOTAL (worst case, still <1s!) ‚úÖ
```

**Typical**: 600-800ms ‚úÖ  
**Worst case**: 900ms ‚úÖ  
**Still under 1 second requirement!** ‚úÖ

## üîß Why Production Needs Different Settings

### 1. Network Latency

**Local**: Direct connection, minimal delay
```
You ‚Üí LiveKit ‚Üí OpenAI
  (fast)      (fast)
```

**Production**: Multiple hops, variable delay
```
You ‚Üí Internet ‚Üí Render.com ‚Üí Internet ‚Üí OpenAI
     (varies)   (cloud)      (varies)
```

**Solution**: Higher `silence_duration_ms` (400ms) accounts for delays

### 2. Network Jitter

**Problem**: Network packets arrive at irregular intervals

**Effect**: VAD might detect "gaps" in speech as silence

**Solution**: Higher `threshold` (0.7) reduces false gap detection

### 3. Server Load

**Render.com**: Shared infrastructure, variable performance

**Effect**: Processing might occasionally spike

**Solution**: More conservative settings for consistency

## üöÄ Deployment Checklist

### Before Deploying to Render.com

- [x] Settings optimized for production (threshold: 0.7)
- [x] Single VAD (no Silero, only OpenAI Server VAD)
- [x] TTS fallback enabled
- [x] Environment variables configured
- [ ] Test from different networks
- [ ] Monitor logs for "cancelled" errors
- [ ] Verify latency meets requirements

### Environment Variables on Render.com

Ensure these are set in Render.com dashboard:

```bash
# Required
OPENAI_API_KEY=sk-...
LIVEKIT_URL=wss://...
LIVEKIT_API_KEY=...
LIVEKIT_API_SECRET=...

# Optional but recommended
VOICE_MODEL=alloy
LOG_LEVEL=INFO
```

### Render.com Specific Configuration

1. **Build Command**:
```bash
pip install -r requirements.txt
```

2. **Start Command**:
```bash
python agent.py
```

3. **Instance Type**:
- Minimum: 512MB RAM
- Recommended: 1GB RAM for stability

4. **Region**:
- Choose closest to your users
- US West (California) for OpenAI proximity

## üß™ Testing in Production

### Test 1: Basic Connectivity

```
1. Deploy to Render.com
2. Check logs for successful startup:
   "‚úÖ Realtime agent ready - PRODUCTION optimized!"
3. Connect from LiveKit Playground
4. Verify connection without errors
```

### Test 2: Latency Check

```
1. Say "Hello"
2. Time until agent responds
3. Expected: 600-900ms ‚úÖ
4. Log should show no "cancelled" errors
```

### Test 3: Stability Over Time

```
1. Have 5-minute conversation
2. Ask multiple questions
3. Verify no dropped responses
4. Check for "cancelled" in logs (should be minimal/none)
```

### Test 4: Network Variations

```
1. Test from WiFi
2. Test from mobile data
3. Test from different locations
4. All should work reliably
```

## ‚ö†Ô∏è Common Production Issues

### Issue 1: Still Seeing "Cancelled"

**Cause**: Network too unstable, threshold still too low

**Fix**: Increase threshold further
```python
threshold=0.75,  # Even more conservative
silence_duration_ms=450,
```

### Issue 2: Latency > 1 Second

**Cause**: Network path is slow

**Possible Solutions**:
1. Change Render.com region (closer to users)
2. Optimize network route
3. Accept 900-1000ms (still acceptable for voice)

**Note**: In production, 800-900ms is normal and acceptable

### Issue 3: Agent Doesn't Hear Clear Speech

**Cause**: Threshold too high for your audio quality

**Fix**: Lower threshold slightly
```python
threshold=0.65,  # Slightly more sensitive
```

### Issue 4: Connection Drops

**Cause**: Render.com free tier limitations

**Solution**:
1. Upgrade to paid tier
2. Ensure worker doesn't sleep (ping endpoint)
3. Configure health checks

## üìä Monitoring Production

### Key Metrics to Watch

1. **Cancelled Rate**: Should be <5%
2. **Average Latency**: 600-800ms
3. **Connection Success**: >95%
4. **Response Completion**: >95%

### Log Patterns

**‚úÖ Healthy**:
```
‚úÖ Realtime agent ready
[No cancelled errors]
[Smooth conversation flow]
```

**‚ö†Ô∏è Warning**:
```
[Occasional cancelled - <5%]
[Latency 800-900ms]
```

**‚ùå Problem**:
```
[Frequent cancelled - >10%]
[Latency >1000ms]
[Connection errors]
```

## üîß Fine-Tuning for Your Environment

### If On AWS/Azure (not Render)

```python
# Might be able to use slightly lower values
threshold=0.65,
silence_duration_ms=350,
```

### If On Render.com (Current)

```python
# Current optimized settings
threshold=0.7,
silence_duration_ms=400,
```

### If On Low-End Infrastructure

```python
# More conservative
threshold=0.75,
silence_duration_ms=500,
```

## üìù Production Settings Summary

```python
# PRODUCTION CONFIGURATION (Render.com)

realtime_model = openai.realtime.RealtimeModel(
    voice=Config.VOICE_MODEL,
    temperature=0.8,
    modalities=["text", "audio"],
    turn_detection=TurnDetection(
        type="server_vad",
        threshold=0.7,              # Production-grade stability
        prefix_padding_ms=300,      # Network-reliable
        silence_duration_ms=400,    # Cloud-optimized
    ),
)

agent = voice.Agent(
    instructions=Config.SYSTEM_PROMPT,
    llm=realtime_model,
    tts=openai.TTS(voice=Config.VOICE_MODEL),
    # No local VAD - cloud stability
)
```

## ‚úÖ Expected Results in Production

After deploying with these settings:

- ‚úÖ **Stability**: Minimal "cancelled" errors (<5%)
- ‚úÖ **Latency**: 600-900ms (acceptable for voice)
- ‚úÖ **Reliability**: Consistent performance
- ‚úÖ **Quality**: Natural conversations
- ‚úÖ **Scalability**: Handles multiple concurrent users

## üöÄ You're Production-Ready!

Your agent is now optimized for:
- ‚òÅÔ∏è **Cloud deployment** (Render.com, AWS, Azure)
- üåê **Network variability** (stable across conditions)
- ‚ö° **Low latency** (600-900ms including network)
- üõ°Ô∏è **Stability** (minimal cancelled responses)

**Deploy to Render.com and test!** üéâ

---

## Quick Reference

| Environment | Threshold | Silence | Expected Latency |
|------------|-----------|---------|------------------|
| **Local Dev** | 0.6 | 300ms | 400-600ms |
| **Production** | 0.7 | 400ms | 600-900ms ‚úÖ |
| **Conservative** | 0.75 | 500ms | 700-1000ms |

