# Phone Call Latency Optimization Guide

## ‚ö° Target: < 1 Second Response Time

**Current Status:** Optimized settings for 600-900ms latency

---

## üéØ Optimized Settings Applied

### Updated agent.py:

```python
turn_detection=TurnDetection(
    type="server_vad",
    threshold=0.75,        # Balanced: not too sensitive, responds faster
    prefix_padding_ms=200, # Reduced from 300ms for quicker response
    silence_duration_ms=500, # Balanced: fast but stable
)
```

### What Changed:

| Setting | Previous | New | Impact |
|---------|----------|-----|--------|
| **Threshold** | 0.8 | **0.75** | Faster detection, slight sensitivity increase |
| **Prefix Padding** | 300ms | **200ms** | 100ms faster trigger |
| **Silence Duration** | 600ms | **500ms** | 100ms faster response |
| **Total Savings** | - | **~200ms** | Significant latency reduction |

---

## üöÄ Apply the Optimization

### Step 1: Restart Agent

```bash
# Stop current agent (Ctrl+C)
python agent.py
```

**Look for new messages:**
```
‚úÖ VAD threshold: 0.75 (balanced: speed + stability)
‚úÖ Silence duration: 500ms (fast response)
‚úÖ Expected latency: 600-900ms target
```

### Step 2: Test Latency

1. **Call your number**
2. **Say "Hello!"** and **start a timer**
3. **Stop when agent starts speaking**
4. **Measure the delay**

**Target:** 600-900ms total

---

## üìä Latency Breakdown (Typical Phone Call)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Total Latency: ~600-900ms                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

You stop speaking
    ‚Üì
    ‚îÇ 500ms - Silence detection (VAD waits for silence)
    ‚ñº
Agent detects turn
    ‚Üì
    ‚îÇ 50-100ms - Network: Phone ‚Üí Twilio ‚Üí Render
    ‚ñº
Audio reaches agent
    ‚Üì
    ‚îÇ 100-200ms - OpenAI Realtime STT (speech-to-text)
    ‚ñº
Text recognized
    ‚Üì
    ‚îÇ 200-300ms - OpenAI GPT-4 (LLM processing)
    ‚ñº
Response generated
    ‚Üì
    ‚îÇ 100-150ms - OpenAI TTS (text-to-speech)
    ‚ñº
Audio generated
    ‚Üì
    ‚îÇ 50-100ms - Network: Agent ‚Üí Render ‚Üí Twilio ‚Üí Phone
    ‚ñº
You hear response

TOTAL: ~600-900ms
```

---

## ‚ö° Additional Optimizations

### 1. Use Shorter System Prompt

**Current prompt is verbose.** Shorter prompt = faster processing.

Update `config.py`:

```python
SYSTEM_PROMPT = """You are a helpful AI phone assistant.

Keep responses VERY brief (1-2 sentences max).
Speak naturally and quickly.
Ask one question at a time.
Be concise."""
```

**Saves:** 50-100ms in LLM processing

### 2. Reduce Temperature (Faster Responses)

Lower temperature = more deterministic = faster.

In `agent.py`:
```python
realtime_model = openai.realtime.RealtimeModel(
    voice=Config.VOICE_MODEL,
    temperature=0.6,  # Reduced from 0.8 for speed
    ...
)
```

**Saves:** 20-50ms

### 3. Deploy Agent on Render.com (Same Region as Webhook)

**Current:** Agent local ‚Üí Higher latency  
**Better:** Agent on Render.com ‚Üí Lower network latency

**Network savings:**
- Local agent: +100-200ms (internet routing)
- Render agent: +20-50ms (internal network)
- **Saves: ~100ms**

### 4. Choose Faster Voice Model

Some OpenAI voices are faster than others.

Try these for speed:
- `alloy` - Fast, clear (good balance)
- `echo` - Fast, slightly robotic
- `nova` - Fast, feminine

In `.env`:
```
VOICE_MODEL=alloy
```

**Saves:** Varies, but alloy is typically fastest

### 5. Use LiveKit Region Close to Users

Check your LiveKit URL. If most users are in:
- **US** ‚Üí Use US LiveKit region
- **Europe** ‚Üí Use EU LiveKit region
- **Asia** ‚Üí Use Asia LiveKit region

**Saves:** 50-200ms depending on distance

---

## üéõÔ∏è Fine-Tuning VAD Settings

If you want to experiment further:

### For Even Lower Latency (Aggressive):

```python
turn_detection=TurnDetection(
    type="server_vad",
    threshold=0.7,         # More sensitive = faster
    prefix_padding_ms=150, # Minimal padding
    silence_duration_ms=400, # Quick detection
)
```

**Pros:** Very fast (~500-700ms total)  
**Cons:** May interrupt occasionally, more sensitive to noise

### For More Stability (Conservative):

```python
turn_detection=TurnDetection(
    type="server_vad",
    threshold=0.8,         # Less sensitive = fewer false triggers
    prefix_padding_ms=300, # More padding
    silence_duration_ms=600, # Wait longer
)
```

**Pros:** Very stable, fewer interruptions  
**Cons:** Slower (~800-1100ms total)

### Current (Balanced - Recommended):

```python
turn_detection=TurnDetection(
    type="server_vad",
    threshold=0.75,        # ‚Üê Current setting
    prefix_padding_ms=200, # ‚Üê Current setting
    silence_duration_ms=500, # ‚Üê Current setting
)
```

**Pros:** Good balance of speed + stability  
**Cons:** None, this is the sweet spot

---

## üìà Latency Testing & Measurement

### How to Measure Accurately:

**Method 1: Manual Timing**
1. Record your phone call
2. Play back and measure with timer
3. From end of your speech ‚Üí start of agent speech

**Method 2: Check Logs**

In agent logs, look for timestamps:
```
[06:27:44] - stream closed (you stopped speaking)
[06:27:45] - [agent starts responding]
```

**Method 3: Multiple Test Calls**
- Make 5-10 test calls
- Measure each
- Average the latency
- Target: < 1 second average

---

## üéØ Optimization Priority

Focus on these in order:

### High Impact (Do First):
1. ‚úÖ **VAD Settings** - Already optimized
2. ‚≠ê **Deploy agent to Render** - Saves ~100ms
3. ‚≠ê **Shorter system prompt** - Saves 50-100ms

### Medium Impact:
4. **Lower temperature** (0.6) - Saves 20-50ms
5. **Choose fast voice** (alloy) - Variable savings
6. **LiveKit region** - Saves 50-200ms if far

### Low Impact:
7. Different OpenAI model (already using fastest)
8. Network optimization (limited control)

---

## üß™ Test Different Scenarios

### Test 1: Quiet Environment
- **Expected:** Best latency (600-700ms)
- VAD detects end of speech quickly

### Test 2: With Background Noise
- **Expected:** Slightly higher (700-900ms)
- VAD needs to distinguish speech from noise

### Test 3: Multiple Back-and-Forth
- **Expected:** Consistent latency
- Should stay < 1 second throughout

### Test 4: Long User Speech
- **Expected:** Same latency
- Latency measured from END of speech

---

## üìä Expected Results

### After Optimization:

| Scenario | Latency | Status |
|----------|---------|--------|
| **Quiet call** | 600-700ms | ‚úÖ Excellent |
| **Normal call** | 700-850ms | ‚úÖ Good |
| **Noisy call** | 850-950ms | ‚úÖ Acceptable |
| **Peak times** | Up to 1000ms | ‚ö†Ô∏è Monitor |

### If > 1 Second:

**Possible causes:**
1. Network congestion (internet or phone)
2. OpenAI API slow (peak usage times)
3. LiveKit far from users (region issue)
4. System prompt too long
5. Agent running locally (deploy to cloud)

---

## üîß Quick Optimization Checklist

Apply these for best latency:

- [ ] Agent restarted with new VAD settings (0.75, 500ms)
- [ ] System prompt shortened (< 100 words)
- [ ] Temperature set to 0.6-0.7
- [ ] Using fast voice (alloy recommended)
- [ ] Agent deployed to Render.com (not local)
- [ ] LiveKit region close to users
- [ ] Tested in quiet environment first

---

## üí° Pro Tips

### 1. Speak Clearly and Pause

**User behavior affects latency:**
- Clear speech ‚Üí Faster recognition
- Definite pause ‚Üí Faster detection
- No "umm" at end ‚Üí Immediate response

### 2. Tell Users to Expect Brief Pause

"There will be a brief pause before I respond" in greeting helps set expectations.

### 3. Monitor Different Times of Day

OpenAI API can be slower during peak hours (US afternoon/evening).

### 4. Consider CDN/Edge Deployment

For global users, consider:
- Multiple Render regions
- Edge deployment (Cloudflare Workers, etc.)
- Regional LiveKit instances

---

## üéØ Summary

**Current Optimization:**
- Threshold: 0.75 (balanced)
- Silence: 500ms (fast)
- Prefix padding: 200ms (reduced)

**Expected Latency:** 600-900ms ‚úÖ

**Next Steps:**
1. Restart agent with new settings
2. Test phone call latency
3. If still > 1s, apply additional optimizations above
4. Consider deploying agent to Render.com

**Most Impact:**
- ‚≠ê Deploy agent to Render: ~100ms saved
- ‚≠ê Shorter prompt: ~50-100ms saved
- ‚≠ê Current VAD settings: ~200ms saved

---

**Your agent should now respond in under 1 second!** ‚ö°

Test it and let me know the results!

